# åŠŸèƒ½æµ‹è¯•ç”¨ä¾‹ç®¡ç†æ¨¡å— - æŠ€æœ¯å®ç°æ–¹æ¡ˆ

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0
> **åˆ›å»ºæ—¥æœŸ**: 2025-01-30
> **ç›®æ ‡**: æä¾›å¯è½åœ°çš„æŠ€æœ¯å®ç°æ–¹æ¡ˆï¼ŒæŒ‡å¯¼å¼€å‘å›¢é˜Ÿå®ŒæˆåŠŸèƒ½æµ‹è¯•æ¨¡å—çš„å¼€å‘

---

## ä¸€ã€æŠ€æœ¯æ¶æ„æ€»è§ˆ

### 1.1 æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      å‰ç«¯å±‚ (React)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ éœ€æ±‚ç®¡ç† â”‚ ç”¨ä¾‹ç®¡ç† â”‚ æ€ç»´å¯¼å›¾ â”‚ çŸ¥è¯†åº“   â”‚ é…ç½®ç®¡ç† â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP/WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     åç«¯å±‚ (FastAPI)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              APIç½‘å…³ & è®¤è¯æˆæƒ                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚éœ€æ±‚æœåŠ¡ â”‚ç”¨ä¾‹æœåŠ¡ â”‚çŸ¥è¯†åº“   â”‚AIç¼–æ’  â”‚æ–‡ä»¶æœåŠ¡ â”‚  â”‚
â”‚  â”‚          â”‚          â”‚æœåŠ¡     â”‚æœåŠ¡     â”‚          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      æ•°æ®å±‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚PostgreSQLâ”‚ pgvector â”‚  MinIO   â”‚  Redis   â”‚å¤–éƒ¨AI APIâ”‚  â”‚
â”‚  â”‚(ä¸šåŠ¡æ•°æ®)â”‚(å‘é‡å­˜å‚¨)â”‚(æ–‡ä»¶å­˜å‚¨)â”‚ (ç¼“å­˜)   â”‚(OpenAIç­‰)â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æŠ€æœ¯æ ˆé€‰å‹

| å±‚çº§ | æŠ€æœ¯é€‰å‹ | è¯´æ˜ |
|------|----------|------|
| **å‰ç«¯** | React 19 + TypeScript | ç±»å‹å®‰å…¨,ç”Ÿæ€ä¸°å¯Œ |
| **å‰ç«¯çŠ¶æ€** | React Query (TanStack Query) | æœåŠ¡ç«¯çŠ¶æ€ç®¡ç† |
| **å‰ç«¯UI** | shadcn/ui + Ant Design | åŸºç¡€ç»„ä»¶ + ä¸šåŠ¡ç»„ä»¶ |
| **æ€ç»´å¯¼å›¾** | ReactFlow | çµæ´»çš„å›¾å½¢åº“ |
| **å¯Œæ–‡æœ¬ç¼–è¾‘** | Tiptap | ç°ä»£åŒ–ç¼–è¾‘å™¨ |
| **åç«¯æ¡†æ¶** | FastAPI | é«˜æ€§èƒ½å¼‚æ­¥æ¡†æ¶ |
| **ORM** | SQLModel | ç±»å‹å®‰å…¨çš„ORM |
| **æ•°æ®åº“** | PostgreSQL 15+ | å…³ç³»å‹æ•°æ®åº“ |
| **å‘é‡æ‰©å±•** | pgvector | å‘é‡ç›¸ä¼¼åº¦æœç´¢ |
| **æ–‡ä»¶å­˜å‚¨** | MinIO | å¯¹è±¡å­˜å‚¨ |
| **ç¼“å­˜** | Redis | ä¼šè¯ç¼“å­˜,ä»»åŠ¡é˜Ÿåˆ— |
| **AIç¼–æ’** | LangChain | LLMåº”ç”¨æ¡†æ¶ |
| **ä»»åŠ¡é˜Ÿåˆ—** | Celery + Redis | å¼‚æ­¥ä»»åŠ¡å¤„ç† |
| **å‘é‡æ£€ç´¢** | pgvector + LangChain | è¯­ä¹‰æœç´¢ |

---

## äºŒã€æ¶æ„é€‰å‹å†³ç­–ï¼šè‡ªç ” vs n8n/Dify

### 2.1 æ–¹æ¡ˆå¯¹æ¯”åˆ†æ

| ç»´åº¦ | **è‡ªç ”æ–¹æ¡ˆ (æ¨è)** | **n8né›†æˆ** | **Difyé›†æˆ** |
|------|-------------------|------------|-------------|
| **å¼€å‘æˆæœ¬** | é«˜ (4-6å‘¨) | ä½ (1-2å‘¨) | ä¸­ (2-3å‘¨) |
| **çµæ´»æ€§** | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ |
| **å¯å®šåˆ¶æ€§** | å®Œå…¨å¯æ§ | å—é™äºn8nèƒ½åŠ› | å—é™äºDifyèƒ½åŠ› |
| **AIæ¨¡å‹æ”¯æŒ** | æ— é™æ‰©å±• | éœ€è‡ªè¡Œé›†æˆèŠ‚ç‚¹ | éœ€é…ç½®Provider |
| **å¤šè½®å¯¹è¯** | æ˜“å®ç° (WebSocket) | éœ€å¤æ‚é…ç½® | æ”¯æŒä½†æœ‰é™åˆ¶ |
| **ä¸Šä¸‹æ–‡ç®¡ç†** | å®Œå…¨å¯æ§ | éœ€æ‰‹åŠ¨ä¼ é€’ | è‡ªåŠ¨ç®¡ç† |
| **å‘é‡æ£€ç´¢** | pgvectoråŸç”Ÿæ”¯æŒ | éœ€å¤–éƒ¨é›†æˆ | å†…ç½®æ”¯æŒ |
| **ç”¨æˆ·ä½“éªŒ** | æ— ç¼é›†æˆ,ä¸€è‡´æ€§å¥½ | è·³è½¬æ„Ÿ,å‰²è£‚ | è·³è½¬æ„Ÿ,å‰²è£‚ |
| **ç»´æŠ¤æˆæœ¬** | ä¸­ (è‡ªç»´æŠ¤) | ä½ (n8nç»´æŠ¤) | ä½ (Difyç»´æŠ¤) |
| **æ€§èƒ½** | é«˜ (å®šåˆ¶ä¼˜åŒ–) | ä¸­ (å¤šå±‚è½¬å‘) | ä¸­ (å¤šå±‚è½¬å‘) |
| **æ•°æ®å®‰å…¨** | å®Œå…¨ç§æœ‰åŒ– | éœ€éƒ¨ç½²n8n | ä¾èµ–Difyéƒ¨ç½² |
| **å­¦ä¹ æˆæœ¬** | éœ€å­¦ä¹ LangChain | éœ€å­¦ä¹ n8n | ä½ (é…ç½®åŒ–) |

### 2.2 æ¨èæ–¹æ¡ˆï¼š**è‡ªç ” + LangChain**

**æ¨èç†ç”±**ï¼š

1. **ç”¨æˆ·ä½“éªŒä¼˜å…ˆ**
   - AIå¯¹è¯ä¸ä¸šåŠ¡åŠŸèƒ½æ— ç¼é›†æˆ
   - å®æ—¶æµå¼è¾“å‡º,ç”¨æˆ·ä½“éªŒæµç•…
   - æ— éœ€è·³è½¬åˆ°å¤–éƒ¨å¹³å°

2. **ä¸šåŠ¡æ·±åº¦å®šåˆ¶**
   - éœ€æ±‚æ¾„æ¸…çš„å¤šè½®å¯¹è¯éœ€è¦ä¸ä¸šåŠ¡æ•°æ®æ·±åº¦ç»‘å®š
   - æµ‹è¯•ç‚¹ç”Ÿæˆéœ€è¦ç»“åˆå†å²ç”¨ä¾‹çŸ¥è¯†åº“
   - ç”¨ä¾‹è¯„å®¡éœ€è¦å®æ—¶åŒæ­¥æ›´æ–°

3. **æŠ€æœ¯å¯æ§æ€§**
   - PostgreSQL + pgvector ä½œä¸ºå‘é‡æ•°æ®åº“,æ— éœ€é¢å¤–ç»„ä»¶
   - LangChain æä¾›æˆç†Ÿçš„LLMç¼–æ’èƒ½åŠ›
   - å¯æ ¹æ®ä¸šåŠ¡éœ€æ±‚çµæ´»è°ƒæ•´Promptå’Œæµç¨‹

4. **æ€§èƒ½ä¸æˆæœ¬**
   - å‡å°‘ä¸­é—´å±‚è½¬å‘,é™ä½å»¶è¿Ÿ
   - pgvector å¼€æºå…è´¹,æ— éœ€é¢å¤–å‘é‡æ•°æ®åº“æˆæœ¬
   - å¯æŒ‰éœ€é€‰æ‹©ä¸åŒAIå‚å•†,æˆæœ¬å¯æ§

5. **å¯æ‰©å±•æ€§**
   - æœªæ¥å¯æ¥å…¥æ›´å¤šAIèƒ½åŠ› (å¦‚è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬ç”Ÿæˆ)
   - å¯æ ¹æ®ä¸šåŠ¡æ•°æ®å¾®è°ƒä¸“å±æ¨¡å‹
   - å¯æ‰©å±•åˆ°å¤šæ¨¡æ€ (è¯­éŸ³ã€è§†é¢‘)

**ä½•æ—¶é€‰æ‹©n8n/Dify**ï¼š
- å›¢é˜ŸæŠ€æœ¯å®åŠ›å¼±,æ— æ³•æ‰¿æ‹…è‡ªç ”
- ä¸šåŠ¡é€»è¾‘ç®€å•,åªæ˜¯ç®€å•çš„LLMè°ƒç”¨
- éœ€è¦å¿«é€ŸéªŒè¯MVP (å¯ä»¥å…ˆç”¨Dify,åæœŸè‡ªç ”)

**ç»“è®º**ï¼š**æ¨èè‡ªç ”æ–¹æ¡ˆ**,ä½¿ç”¨ LangChain ä½œä¸ºAIç¼–æ’æ¡†æ¶ã€‚

---

## ä¸‰ã€æ•°æ®åº“è®¾è®¡

### 3.1 æ•°æ®åº“æ‰©å±•å®‰è£…

é¦–å…ˆéœ€è¦åœ¨PostgreSQLä¸­å®‰è£… pgvector æ‰©å±•ï¼š

```sql
-- è¿æ¥åˆ°æ•°æ®åº“
\c sisyphus

-- å®‰è£… pgvector æ‰©å±•
CREATE EXTENSION IF NOT EXISTS vector;

-- éªŒè¯å®‰è£…
SELECT * FROM pg_extension WHERE extname = 'vector';
```

### 3.2 æ ¸å¿ƒæ•°æ®è¡¨è®¾è®¡

#### 3.2.1 AIé…ç½®è¡¨ (ai_provider_configs)

```sql
CREATE TABLE ai_provider_configs (
    id SERIAL PRIMARY KEY,
    provider_name VARCHAR(50) NOT NULL,          -- OpenAI/Anthropic/ç­‰
    provider_type VARCHAR(50) NOT NULL,          -- openai/anthropic/qwen
    api_key_encrypted TEXT NOT NULL,             -- AESåŠ å¯†å­˜å‚¨
    api_endpoint TEXT,                           -- è‡ªå®šä¹‰endpoint
    model_name VARCHAR(100) NOT NULL,            -- gpt-4/claude-3-opusç­‰
    temperature DECIMAL(3,2) DEFAULT 0.7,        -- 0.00-1.00
    max_tokens INTEGER DEFAULT 4000,
    is_enabled BOOLEAN DEFAULT TRUE,
    is_default BOOLEAN DEFAULT FALSE,
    user_id INTEGER NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    CONSTRAINT unique_user_provider UNIQUE (user_id, provider_type)
);

-- ç´¢å¼•
CREATE INDEX idx_ai_configs_user ON ai_provider_configs(user_id);
CREATE INDEX idx_ai_configs_enabled ON ai_provider_configs(is_enabled, is_default);
```

#### 3.2.2 éœ€æ±‚è¡¨ (requirements)

```sql
CREATE TABLE requirements (
    id SERIAL PRIMARY KEY,
    requirement_id VARCHAR(50) UNIQUE NOT NULL,   -- REQ-2025-001
    name VARCHAR(255) NOT NULL,
    module_id VARCHAR(50),                        -- ç¦…é“æ¨¡å—ID
    module_name VARCHAR(100) NOT NULL,
    iteration VARCHAR(50),
    priority VARCHAR(20) NOT NULL,                -- high/medium/low

    -- éœ€æ±‚å†…å®¹
    description TEXT NOT NULL,                    -- Markdownæ ¼å¼
    attachments TEXT[],                           -- MinIOå­˜å‚¨è·¯å¾„æ•°ç»„

    -- AIæ¾„æ¸…è®°å½•
    ai_conversation_id VARCHAR(100),              -- å…³è”å¯¹è¯å†å²
    clarification_status VARCHAR(20) DEFAULT 'draft', -- draft/clarifying/confirmed
    risk_points TEXT[],                           -- JSONæ•°ç»„

    -- çŠ¶æ€
    status VARCHAR(20) DEFAULT 'draft',           -- draft/review/approved/cancelled

    -- å…³è”
    test_case_suite_id INTEGER,                   -- å…³è”çš„ç”¨ä¾‹é›†

    -- å…ƒæ•°æ®
    created_by INTEGER NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    version INTEGER DEFAULT 1
);

-- ç´¢å¼•
CREATE INDEX idx_requirements_req_id ON requirements(requirement_id);
CREATE INDEX idx_requirements_module ON requirements(module_id);
CREATE INDEX idx_requirements_status ON requirements(status);
CREATE INDEX idx_requirements_created_by ON requirements(created_by);

-- å…¨æ–‡æœç´¢ç´¢å¼• (PostgreSQLå†…ç½®)
CREATE INDEX idx_requirements_search ON requirements USING gin(to_tsvector('chinese', name || ' ' || description));
```

#### 3.2.3 AIå¯¹è¯å†å²è¡¨ (ai_conversations)

```sql
CREATE TABLE ai_conversations (
    id SERIAL PRIMARY KEY,
    conversation_id VARCHAR(100) UNIQUE NOT NULL, -- å¯¹è¯å”¯ä¸€æ ‡è¯†
    requirement_id INTEGER REFERENCES requirements(id),

    -- ä¼šè¯ä¿¡æ¯
    session_type VARCHAR(50) NOT NULL,            -- requirement_clarification/test_point_generation
    ai_model_used VARCHAR(100),                   -- ä½¿ç”¨çš„AIæ¨¡å‹

    -- æ¶ˆæ¯å­˜å‚¨
    messages JSONB NOT NULL,                      -- æ¶ˆæ¯å†å² [{role, content, timestamp}]

    -- å…ƒæ•°æ®
    created_by INTEGER NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç´¢å¼•
CREATE INDEX idx_ai_conv_conversation_id ON ai_conversations(conversation_id);
CREATE INDEX idx_ai_conv_requirement ON ai_conversations(requirement_id);
```

#### 3.2.4 æµ‹è¯•ç‚¹è¡¨ (test_points)

```sql
CREATE TABLE test_points (
    id SERIAL PRIMARY KEY,
    requirement_id INTEGER NOT NULL REFERENCES requirements(id),
    category VARCHAR(50) NOT NULL,                -- functional/performance/security/compatibility
    sub_category VARCHAR(50),                     -- æ­£å¸¸æµç¨‹/å¼‚å¸¸æµç¨‹/è¾¹ç•Œå€¼

    title VARCHAR(255) NOT NULL,
    description TEXT,
    priority VARCHAR(10) NOT NULL,                -- p0/p1/p2/p3
    risk_level VARCHAR(20),                       -- high/medium/low

    -- AIç”Ÿæˆä¿¡æ¯
    is_ai_generated BOOLEAN DEFAULT TRUE,
    confidence_score DECIMAL(3,2),                -- 0.00-1.00

    -- çŠ¶æ€
    status VARCHAR(20) DEFAULT 'draft',           -- draft/approved/rejected

    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç´¢å¼•
CREATE INDEX idx_test_points_requirement ON test_points(requirement_id);
CREATE INDEX idx_test_points_category ON test_points(category, priority);
```

#### 3.2.5 æµ‹è¯•ç”¨ä¾‹è¡¨ (test_cases)

```sql
CREATE TABLE test_cases (
    id SERIAL PRIMARY KEY,
    case_id VARCHAR(50) UNIQUE NOT NULL,          -- TC-2025-001-001

    -- å…³è”
    requirement_id INTEGER NOT NULL REFERENCES requirements(id),
    test_suite_id INTEGER,                        -- å…³è”ç”¨ä¾‹é›†
    test_point_id INTEGER REFERENCES test_points(id),

    -- åŸºç¡€ä¿¡æ¯
    module_name VARCHAR(100) NOT NULL,
    page_name VARCHAR(100) NOT NULL,
    title VARCHAR(255) NOT NULL,
    priority VARCHAR(10) NOT NULL,                -- p0/p1/p2/p3
    case_type VARCHAR(50) NOT NULL,               -- functional/performance/security

    -- ç”¨ä¾‹å†…å®¹
    preconditions JSONB,                          -- å‰ç½®æ¡ä»¶æ•°ç»„
    steps JSONB NOT NULL,                         -- æµ‹è¯•æ­¥éª¤ [{step_number, action, expected_result}]
    tags TEXT[],                                  -- æ ‡ç­¾æ•°ç»„

    -- å…ƒæ•°æ®
    is_automated BOOLEAN DEFAULT FALSE,
    complexity VARCHAR(20),                       -- low/medium/high
    estimated_time INTEGER DEFAULT 0,             -- é¢„ä¼°æ‰§è¡Œæ—¶é—´(åˆ†é’Ÿ)

    -- AIç”Ÿæˆä¿¡æ¯
    is_ai_generated BOOLEAN DEFAULT FALSE,
    ai_model VARCHAR(100),

    -- çŠ¶æ€
    status VARCHAR(20) DEFAULT 'draft',           -- draft/review/approved/cancelled

    -- åˆ›å»ºä¿¡æ¯
    created_by INTEGER NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    version INTEGER DEFAULT 1
);

-- ç´¢å¼•
CREATE INDEX idx_test_cases_case_id ON test_cases(case_id);
CREATE INDEX idx_test_cases_requirement ON test_cases(requirement_id);
CREATE INDEX idx_test_cases_suite ON test_cases(test_suite_id);
CREATE INDEX idx_test_cases_priority ON test_cases(priority);
CREATE INDEX idx_test_cases_module_page ON test_cases(module_name, page_name);

-- å…¨æ–‡æœç´¢
CREATE INDEX idx_test_cases_search ON test_cases USING gin(to_tsvector('chinese', title || ' ' || coalesce(preconditions::text, '')));
```

#### 3.2.6 æµ‹è¯•ç”¨ä¾‹çŸ¥è¯†åº“è¡¨ (test_case_knowledge)

```sql
-- ä½¿ç”¨ pgvector å­˜å‚¨å‘é‡
CREATE TABLE test_case_knowledge (
    id SERIAL PRIMARY KEY,
    test_case_id INTEGER NOT NULL REFERENCES test_cases(id),

    -- å‘é‡åŒ–æ•°æ®
    embedding vector(1536),                      -- OpenAI: 1536ç»´, BERT: 768ç»´
    embedding_model VARCHAR(100) NOT NULL,        -- text-embedding-3-small/bert-base-chinese

    -- å…ƒæ•°æ® (ç”¨äºè¿‡æ»¤)
    module_name VARCHAR(100) NOT NULL,
    priority VARCHAR(10) NOT NULL,
    case_type VARCHAR(50) NOT NULL,
    tags TEXT[],

    -- è´¨é‡æŒ‡æ ‡
    quality_score DECIMAL(3,1) DEFAULT 0.0,       -- 0.0-10.0
    usage_count INTEGER DEFAULT 0,                -- è¢«å¼•ç”¨æ¬¡æ•°

    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    -- å”¯ä¸€çº¦æŸ
    CONSTRAINT unique_case_embedding UNIQUE (test_case_id, embedding_model)
);

-- ç´¢å¼•
CREATE INDEX idx_knowledge_embedding ON test_case_knowledge USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
CREATE INDEX idx_knowledge_case ON test_case_knowledge(test_case_id);
```

**è¯´æ˜**:
- `ivfflat` ç´¢å¼•é€‚åˆå¤§è§„æ¨¡å‘é‡æ£€ç´¢ (ç™¾ä¸‡çº§)
- `vector_cosine_ops` ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
- `lists = 100` æ˜¯ç´¢å¼•å‚æ•°,æ ¹æ®æ•°æ®é‡è°ƒæ•´

#### 3.2.7 ç”¨ä¾‹æ¨¡æ¿è¡¨ (test_case_templates)

```sql
CREATE TABLE test_case_templates (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    description TEXT,
    category VARCHAR(50),                        -- form_submission/list_query/file_uploadç­‰

    -- æ¨¡æ¿å†…å®¹
    template_structure JSONB NOT NULL,           -- æ¨¡æ¿ç»“æ„

    -- ç»Ÿè®¡
    usage_count INTEGER DEFAULT 0,

    -- å…ƒæ•°æ®
    is_system BOOLEAN DEFAULT FALSE,             -- ç³»ç»Ÿæ¨¡æ¿/ç”¨æˆ·è‡ªå®šä¹‰
    created_by INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç´¢å¼•
CREATE INDEX idx_templates_category ON test_case_templates(category);
```

#### 3.2.8 æ–‡ä»¶å­˜å‚¨è®°å½•è¡¨ (file_attachments)

```sql
CREATE TABLE file_attachments (
    id SERIAL PRIMARY KEY,
    file_id VARCHAR(100) UNIQUE NOT NULL,        -- UUID

    -- æ–‡ä»¶ä¿¡æ¯
    filename VARCHAR(255) NOT NULL,
    file_type VARCHAR(50) NOT NULL,              -- image/png/application/pdf
    file_size BIGINT NOT NULL,                   -- å­—èŠ‚
    file_path TEXT NOT NULL,                     -- MinIOå­˜å‚¨è·¯å¾„

    -- å…³è”
    entity_type VARCHAR(50) NOT NULL,            -- requirement/test_case
    entity_id INTEGER NOT NULL,

    -- å…ƒæ•°æ®
    uploaded_by INTEGER NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- ç´¢å¼•
CREATE INDEX idx_attachments_entity ON file_attachments(entity_type, entity_id);
```

### 3.3 ERå›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  requirements   â”‚â”€â”€â”€1:1â”€â”‚  test_cases     â”‚
â”‚                 â”‚       â”‚                 â”‚
â”‚ - requirement_idâ”‚       â”‚ - case_id       â”‚
â”‚ - name          â”‚       â”‚ - title         â”‚
â”‚ - description   â”‚       â”‚ - steps         â”‚
â”‚ - module_id     â”‚       â”‚ - preconditions â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                          â”‚
         â”‚1:N                      â”‚1:1
         â†“                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  test_points    â”‚       â”‚test_case_       â”‚
â”‚                 â”‚       â”‚  knowledge      â”‚
â”‚ - title         â”‚       â”‚                 â”‚
â”‚ - category      â”‚       â”‚ - embedding     â”‚
â”‚ - priority      â”‚       â”‚ - quality_score â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†‘                          â†‘
         â”‚                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ai_provider_configs               â”‚
â”‚                                            â”‚
â”‚ - provider_name                            â”‚
â”‚ - api_key_encrypted                        â”‚
â”‚ - model_name                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å››ã€AIé›†æˆæ–¹æ¡ˆ (åŸºäºLangChain + LangGraph)

### 4.1 ä¸ºä»€ä¹ˆéœ€è¦LangGraph?

**æ ¸å¿ƒé—®é¢˜**: éœ€æ±‚æ¾„æ¸…æ˜¯ä¸€ä¸ª**å¤æ‚çš„å¤šè½®å¯¹è¯æµç¨‹**,æ¶‰åŠ:
- å¤šè½®å¯¹è¯äº¤äº’ (AIæé—® â†’ ç”¨æˆ·å›ç­” â†’ AIç»§ç»­åˆ†æ)
- ç»“æ„åŒ–çŠ¶æ€ç®¡ç† (éœ€æ±‚æ–‡æ¡£ã€é£é™©ç‚¹ã€å¾…ç¡®è®¤é—®é¢˜ã€å·²ç¡®è®¤é—®é¢˜)
- æ¡ä»¶åˆ†æ”¯ (æ ¹æ®AIåˆ†æç»“æœå†³å®šä¸‹ä¸€æ­¥:ç»§ç»­æé—® or ç»“æŸæ¾„æ¸…)
- äººå·¥å¹²é¢„ (æš‚åœæ‰§è¡Œ,ç­‰å¾…ç”¨æˆ·è¾“å…¥åç»§ç»­)
- çŠ¶æ€æŒä¹…åŒ– (å³ä½¿æœåŠ¡é‡å¯,å¯¹è¯çŠ¶æ€ä¹Ÿä¸ä¸¢å¤±)

**LangChain ConversationChainçš„å±€é™**:
- âŒ åªèƒ½ä¿å­˜æ¶ˆæ¯å†å²,æ— æ³•ç®¡ç†ç»“æ„åŒ–çŠ¶æ€
- âŒ åªèƒ½çº¿æ€§å¯¹è¯,æ— æ³•æ ¹æ®æ¡ä»¶è·³è½¬
- âŒ æ— äººå·¥å¹²é¢„èƒ½åŠ›
- âŒ çŠ¶æ€éœ€è¦æ‰‹åŠ¨æŒä¹…åŒ–

**LangGraphçš„ä¼˜åŠ¿**:
- âœ… **ç»“æ„åŒ–çŠ¶æ€**: éœ€æ±‚æ–‡æ¡£ã€é£é™©ç‚¹ã€é—®é¢˜åˆ—è¡¨å„è‡ªç‹¬ç«‹å­˜å‚¨
- âœ… **æµç¨‹æ§åˆ¶**: æ”¯æŒæ¡ä»¶è¾¹ã€å¾ªç¯ã€åˆ†æ”¯
- âœ… **äººå·¥å¹²é¢„**: å¯åœ¨ä»»æ„èŠ‚ç‚¹æš‚åœ,ç­‰å¾…ç”¨æˆ·è¾“å…¥
- âœ… **çŠ¶æ€æŒä¹…åŒ–**: å†…ç½®PostgreSQL checkpointer
- âœ… **å¯è§‚æµ‹æ€§**: å¯è§†åŒ–çŠ¶æ€å›¾,è°ƒè¯•æ–¹ä¾¿

### 4.2 LangChain + LangGraphæ¶æ„è®¾è®¡

```python
backend/app/services/ai/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base.py                    # AIæœåŠ¡åŸºç±»
â”œâ”€â”€ llm_service.py             # LLMè°ƒç”¨æœåŠ¡ (æ”¯æŒå¤šå‚å•†)
â”œâ”€â”€ embedding_service.py       # å‘é‡åŒ–æœåŠ¡
â”œâ”€â”€ vector_store_service.py    # å‘é‡æ£€ç´¢æœåŠ¡
â”œâ”€â”€ prompt_templates.py        # Promptæ¨¡æ¿ç®¡ç†
â”œâ”€â”€ graphs/                    # LangGraphçŠ¶æ€å›¾ (NEW!)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ requirement_clarification_graph.py   # éœ€æ±‚æ¾„æ¸…çŠ¶æ€å›¾ â­
â”‚   â”œâ”€â”€ test_point_generation_graph.py      # æµ‹è¯•ç‚¹ç”ŸæˆçŠ¶æ€å›¾
â”‚   â””â”€â”€ test_case_generation_graph.py       # ç”¨ä¾‹ç”ŸæˆçŠ¶æ€å›¾
â”œâ”€â”€ chains/                    # ç®€å•çš„LangChainé“¾
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ simple_tasks.py        # ç®€å•ä»»åŠ¡é“¾
â””â”€â”€ tools/                     # AIå·¥å…·
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ knowledge_retrieval.py  # çŸ¥è¯†åº“æ£€ç´¢
    â””â”€â”€ risk_analyzer.py        # é£é™©åˆ†æ
```

### 4.3 æ ¸å¿ƒä»£ç å®ç°

#### 4.3.1 AIæœåŠ¡åŸºç±»

```python
# backend/app/services/ai/base.py
from abc import ABC, abstractmethod
from typing import Optional, Dict, Any, List
from langchain.llms.base import LLM
from langchain.embeddings.base import Embeddings

class AIServiceBase(ABC):
    """AIæœåŠ¡åŸºç±»"""

    def __init__(self, provider_config: Dict[str, Any]):
        self.provider_config = provider_config
        self._llm: Optional[LLM] = None
        self._embeddings: Optional[Embeddings] = None

    @abstractmethod
    async def get_llm(self) -> LLM:
        """è·å–LLMå®ä¾‹"""
        pass

    @abstractmethod
    async def get_embeddings(self) -> Embeddings:
        """è·å–Embeddingå®ä¾‹"""
        pass

    def encrypt_api_key(self, api_key: str) -> str:
        """åŠ å¯†API Key (ä½¿ç”¨cryptographyåº“)"""
        from cryptography.fernet import Fernet
        # å®ç°åŠ å¯†é€»è¾‘
        pass

    def decrypt_api_key(self, encrypted_key: str) -> str:
        """è§£å¯†API Key"""
        from cryptography.fernet import Fernet
        # å®ç°è§£å¯†é€»è¾‘
        pass
```

#### 4.2.2 å¤šå‚å•†LLMæ”¯æŒ

```python
# backend/app/services/ai/llm_service.py
from typing import Dict, Any, Optional
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_community.chat_models import QianfanChatEndpoint  # ç™¾åº¦æ–‡å¿ƒ
from .base import AIServiceBase

class MultiVendorLLMService(AIServiceBase):
    """å¤šå‚å•†LLMæœåŠ¡"""

    async def get_llm(self):
        """æ ¹æ®é…ç½®è¿”å›å¯¹åº”å‚å•†çš„LLMå®ä¾‹"""
        provider_type = self.provider_config["provider_type"]

        if provider_type == "openai":
            return ChatOpenAI(
                model=self.provider_config["model_name"],
                temperature=self.provider_config.get("temperature", 0.7),
                max_tokens=self.provider_config.get("max_tokens", 4000),
                openai_api_key=self.decrypt_api_key(self.provider_config["api_key_encrypted"]),
                openai_api_base=self.provider_config.get("api_endpoint"),
            )

        elif provider_type == "anthropic":
            return ChatAnthropic(
                model=self.provider_config["model_name"],
                temperature=self.provider_config.get("temperature", 0.7),
                max_tokens=self.provider_config.get("max_tokens", 4000),
                anthropic_api_key=self.decrypt_api_key(self.provider_config["api_key_encrypted"]),
            )

        elif provider_type == "qwen":  # é˜¿é‡Œäº‘é€šä¹‰åƒé—®
            from langchain_community.chat_models import Tongyi
            return Tongyi(
                dashscope_api_key=self.decrypt_api_key(self.provider_config["api_key_encrypted"]),
                model_name=self.provider_config["model_name"],
            )

        elif provider_type == "qianfan":  # ç™¾åº¦æ–‡å¿ƒ
            return QianfanChatEndpoint(
                qianfan_api_key=self.decrypt_api_key(self.provider_config["api_key_encrypted"]),
                model=self.provider_config["model_name"],
            )

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„AIå‚å•†: {provider_type}")
```

#### 4.2.3 å‘é‡åŒ–æœåŠ¡

```python
# backend/app/services/ai/embedding_service.py
from typing import List
from langchain_openai import OpenAIEmbeddings
from langchain_community.embeddings import HuggingFaceEmbeddings
from .base import AIServiceBase

class EmbeddingService(AIServiceBase):
    """å‘é‡åŒ–æœåŠ¡"""

    async def get_embeddings(self):
        """è·å–Embeddingæ¨¡å‹"""
        provider_type = self.provider_config["provider_type"]

        if provider_type == "openai":
            return OpenAIEmbeddings(
                model="text-embedding-3-small",  # 1536ç»´
                openai_api_key=self.decrypt_api_key(self.provider_config["api_key_encrypted"]),
            )

        else:
            # ä½¿ç”¨å¼€æºæ¨¡å‹ (éœ€è¦æœ¬åœ°éƒ¨ç½²æˆ–ä½¿ç”¨API)
            return HuggingFaceEmbeddings(
                model_name="shibing624/text2vec-base-chinese",  # ä¸­æ–‡å‘é‡æ¨¡å‹
            )

    async def embed_text(self, text: str) -> List[float]:
        """å¯¹å•ä¸ªæ–‡æœ¬å‘é‡åŒ–"""
        embeddings = await self.get_embeddings()
        return await embeddings.aembed_query(text)

    async def embed_texts(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡å‘é‡åŒ–"""
        embeddings = await self.get_embeddings()
        return await embeddings.aembed_documents(texts)
```

#### 4.2.4 å‘é‡æ£€ç´¢æœåŠ¡

```python
# backend/app/services/ai/vector_store_service.py
from typing import List, Optional, Dict, Any
from langchain.vectorstores import PGVector
from langchain.docstore.document import Document
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.db import get_session
from app.models.test_case import TestCase
from .embedding_service import EmbeddingService

class VectorStoreService:
    """å‘é‡æ£€ç´¢æœåŠ¡"""

    def __init__(self, embedding_service: EmbeddingService):
        self.embedding_service = embedding_service

    async def get_vector_store(self) -> PGVector:
        """è·å–PostgreSQLå‘é‡å­˜å‚¨å®ä¾‹"""
        embeddings = await self.embedding_service.get_embeddings()

        return PGVector(
            connection_string="postgresql+asyncpg://user:pass@localhost/sisyphus",
            collection_name="test_case_knowledge",
            embedding_function=embeddings,
        )

    async def similarity_search(
        self,
        query: str,
        k: int = 5,
        filter: Optional[Dict[str, Any]] = None,
    ) -> List[Document]:
        """ç›¸ä¼¼åº¦æœç´¢"""
        vector_store = await self.get_vector_store()

        return await vector_store.asimilarity_search(
            query=query,
            k=k,
            filter=filter,  # å¦‚ {"module_name": "ç”¨æˆ·ç®¡ç†", "priority": "p0"}
        )

    async def add_test_case_to_knowledge(
        self,
        test_case: TestCase,
        session: AsyncSession,
    ):
        """å°†æµ‹è¯•ç”¨ä¾‹æ·»åŠ åˆ°çŸ¥è¯†åº“"""
        from app.models.test_case_knowledge import TestCaseKnowledge

        # 1. æ„å»ºæ–‡æœ¬å†…å®¹ (æ ‡é¢˜ + å‰ç½®æ¡ä»¶ + æ­¥éª¤)
        text_content = f"""
        ç”¨ä¾‹æ ‡é¢˜: {test_case.title}
        æ‰€å±æ¨¡å—: {test_case.module_name}
        ä¼˜å…ˆçº§: {test_case.priority}
        å‰ç½®æ¡ä»¶: {'; '.join(test_case.preconditions or [])}
        æµ‹è¯•æ­¥éª¤: {'; '.join([step['action'] for step in test_case.steps])}
        """

        # 2. å‘é‡åŒ–
        embedding = await self.embedding_service.embed_text(text_content)

        # 3. å­˜å‚¨åˆ°æ•°æ®åº“
        knowledge = TestCaseKnowledge(
            test_case_id=test_case.id,
            embedding=embedding,
            embedding_model=self.embedding_service.provider_config["provider_type"],
            module_name=test_case.module_name,
            priority=test_case.priority,
            case_type=test_case.case_type,
            tags=test_case.tags,
            quality_score=8.0,  # å¯ä»¥é€šè¿‡AIè¯„ä¼°
        )

        session.add(knowledge)
        await session.commit()
```

#### 4.2.5 éœ€æ±‚æ¾„æ¸…é“¾

```python
# backend/app/services/ai/chains/requirement_clarification_chain.py
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from typing import Dict, Any

from ..llm_service import MultiVendorLLMService

class RequirementClarificationChain:
    """éœ€æ±‚æ¾„æ¸…é“¾ - å¤šè½®å¯¹è¯"""

    def __init__(self, llm_service: MultiVendorLLMService):
        self.llm_service = llm_service

    def get_prompt_template(self) -> PromptTemplate:
        """æ„å»ºPromptæ¨¡æ¿"""
        template = """
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„äº§å“ç»ç†å’Œæµ‹è¯•ä¸“å®¶,è´Ÿè´£å¸®åŠ©ç”¨æˆ·å°†ç¢ç‰‡åŒ–çš„éœ€æ±‚è½¬åŒ–ä¸ºå®Œæ•´çš„éœ€æ±‚æ–‡æ¡£ã€‚

## ç”¨æˆ·å½“å‰éœ€æ±‚
{input}

## å†å²å¯¹è¯
{history}

## ä½ çš„ä»»åŠ¡
1. åˆ†æç”¨æˆ·æä¾›çš„éœ€æ±‚æè¿°å’Œæˆªå›¾,è¯†åˆ«ä¸å®Œæ•´ä¹‹å¤„
2. æå‡ºé’ˆå¯¹æ€§çš„é—®é¢˜æ¥æ¾„æ¸…éœ€æ±‚,åŒ…æ‹¬:
   - åŠŸèƒ½è¾¹ç•Œ (ä»€ä¹ˆæ˜¯in scope,ä»€ä¹ˆæ˜¯out of scope)
   - å¼‚å¸¸åœºæ™¯ (å¤±è´¥åœºæ™¯ã€è¾¹ç•Œæ¡ä»¶)
   - éåŠŸèƒ½éœ€æ±‚ (æ€§èƒ½ã€å®‰å…¨ã€å…¼å®¹æ€§)
   - é£é™©ç‚¹ (æ½œåœ¨çš„æŠ€æœ¯é£é™©ã€ä¸šåŠ¡é£é™©)
3. æ¯æ¬¡æé—®3-5ä¸ªé—®é¢˜,é¿å…ä¸€æ¬¡æ€§æé—®å¤ªå¤š
4. ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€,é¿å…è¿‡äºæŠ€æœ¯åŒ–

## å›ç­”æ ¼å¼
è¯·ç”¨ä»¥ä¸‹æ ¼å¼å›ç­”:

### ğŸ” éœ€è¦ç¡®è®¤çš„é—®é¢˜
1. [é—®é¢˜1]
2. [é—®é¢˜2]
3. [é—®é¢˜3]

### âš ï¸ è¯†åˆ«åˆ°çš„é£é™©
- [é£é™©1]
- [é£é™©2]

### ğŸ’¡ å»ºè®®
[å¯é€‰çš„æ”¹è¿›å»ºè®®]

ç°åœ¨,è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚å¼€å§‹æé—®ã€‚
"""
        return PromptTemplate(
            input_variables=["input", "history"],
            template=template,
        )

    async def aclarify_requirement(
        self,
        user_input: str,
        conversation_history: list,
    ) -> Dict[str, Any]:
        """æ‰§è¡Œéœ€æ±‚æ¾„æ¸…"""
        # 1. è·å–LLM
        llm = await self.llm_service.get_llm()

        # 2. æ„å»ºå¯¹è¯é“¾
        memory = ConversationBufferMemory()
        for msg in conversation_history:
            if msg["role"] == "user":
                memory.chat_memory.add_user_message(msg["content"])
            else:
                memory.chat_memory.add_ai_message(msg["content"])

        prompt = self.get_prompt_template()
        chain = ConversationChain(
            llm=llm,
            prompt=prompt,
            memory=memory,
            verbose=True,
        )

        # 3. æ‰§è¡Œ
        response = await chain.apredict(input=user_input)

        return {
            "response": response,
            "conversation_history": conversation_history + [
                {"role": "user", "content": user_input},
                {"role": "assistant", "content": response},
            ],
        }
```

#### 4.2.6 æµ‹è¯•ç‚¹ç”Ÿæˆé“¾

```python
# backend/app/services/ai/chains/test_point_generation_chain.py
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from typing import List, Dict, Any

from ..llm_service import MultiVendorLLMService
from ..tools.knowledge_retrieval import KnowledgeRetrievalTool

class TestPointGenerationChain:
    """æµ‹è¯•ç‚¹ç”Ÿæˆé“¾"""

    def __init__(self, llm_service: MultiVendorLLMService):
        self.llm_service = llm_service
        self.knowledge_tool = KnowledgeRetrievalTool()

    def get_prompt_template(self) -> PromptTemplate:
        """æ„å»ºPromptæ¨¡æ¿"""
        template = """
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æµ‹è¯•ä¸“å®¶,è´Ÿè´£æ ¹æ®éœ€æ±‚æ–‡æ¡£ç”Ÿæˆå…¨é¢çš„æµ‹è¯•ç‚¹ã€‚

## éœ€æ±‚æ–‡æ¡£
{requirement_text}

## å†å²ç›¸å…³ç”¨ä¾‹ (å‚è€ƒ)
{related_test_cases}

## ä½ çš„ä»»åŠ¡
åŸºäºéœ€æ±‚æ–‡æ¡£ç”Ÿæˆæµ‹è¯•ç‚¹,è¦†ç›–ä»¥ä¸‹ç»´åº¦:

### 1. åŠŸèƒ½æµ‹è¯•ç‚¹
- æ­£å¸¸æµç¨‹ (Happy Path)
- å¼‚å¸¸æµç¨‹ (Error Handling)
- è¾¹ç•Œå€¼ (Boundary)
- æ•°æ®éªŒè¯ (Data Validation)

### 2. æ€§èƒ½æµ‹è¯•ç‚¹
- å“åº”æ—¶é—´
- å¹¶å‘å‹åŠ›
- å¤§æ•°æ®é‡

### 3. å®‰å…¨æµ‹è¯•ç‚¹
- æƒé™æ§åˆ¶
- æ•°æ®åŠ å¯†
- æ³¨å…¥æ”»å‡»é˜²æŠ¤

### 4. å…¼å®¹æ€§æµ‹è¯•ç‚¹
- æµè§ˆå™¨å…¼å®¹
- ç³»ç»Ÿå…¼å®¹
- åˆ†è¾¨ç‡é€‚é…

### 5. æ˜“ç”¨æ€§æµ‹è¯•ç‚¹
- ç”¨æˆ·ä½“éªŒ
- äº¤äº’è®¾è®¡
- é”™è¯¯æç¤ºå‹å¥½æ€§

## è¾“å‡ºæ ¼å¼ (JSON)
è¯·è¾“å‡ºä»¥ä¸‹JSONæ ¼å¼çš„æµ‹è¯•ç‚¹åˆ—è¡¨:

```json
{{
  "test_points": [
    {{
      "category": "functional",
      "sub_category": "æ­£å¸¸æµç¨‹",
      "title": "æ‰‹æœºå·æ­£ç¡®+éªŒè¯ç æ­£ç¡®â†’ç™»å½•æˆåŠŸ",
      "description": "éªŒè¯æ­£å¸¸çš„ç™»å½•æµç¨‹",
      "priority": "p0",
      "risk_level": "low"
    }},
    {{
      "category": "functional",
      "sub_category": "å¼‚å¸¸æµç¨‹",
      "title": "éªŒè¯ç é”™è¯¯â†’æç¤ºé”™è¯¯ä¿¡æ¯",
      "description": "éªŒè¯è¾“å…¥é”™è¯¯éªŒè¯ç æ—¶çš„å¤„ç†",
      "priority": "p1",
      "risk_level": "medium"
    }}
  ]
}}
```

ç°åœ¨,è¯·æ ¹æ®éœ€æ±‚æ–‡æ¡£ç”Ÿæˆæµ‹è¯•ç‚¹ã€‚
"""
        return PromptTemplate(
            input_variables=["requirement_text", "related_test_cases"],
            template=template,
        )

    async def agenerate_test_points(
        self,
        requirement_text: str,
        requirement_id: int,
    ) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæµ‹è¯•ç‚¹"""
        # 1. æ£€ç´¢ç›¸å…³å†å²ç”¨ä¾‹
        related_cases = await self.knowledge_tool.aretrieve_similar_cases(
            query=requirement_text,
            k=5,
        )
        related_cases_text = "\n".join([case.page_content for case in related_cases])

        # 2. è·å–LLM
        llm = await self.llm_service.get_llm()

        # 3. æ„å»ºé“¾
        prompt = self.get_prompt_template()
        chain = LLMChain(llm=llm, prompt=prompt)

        # 4. æ‰§è¡Œ
        response = await chain.apredict(
            requirement_text=requirement_text,
            related_test_cases=related_cases_text,
        )

        # 5. è§£æJSON
        import json
        try:
            result = json.loads(response)
            return result["test_points"]
        except json.JSONDecodeError:
            # å¦‚æœAIè¾“å‡ºä¸è§„èŒƒ,ä½¿ç”¨æ­£åˆ™æå–JSON
            import re
            json_match = re.search(r'```json\n(.*?)\n```', response, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group(1))
                return result["test_points"]
            else:
                raise ValueError("AIè¾“å‡ºçš„æ ¼å¼ä¸ç¬¦åˆè¦æ±‚")
```

#### 4.2.7 æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆé“¾

```python
# backend/app/services/ai/chains/test_case_generation_chain.py
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from typing import List, Dict, Any

from ..llm_service import MultiVendorLLMService

class TestCaseGenerationChain:
    """æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆé“¾"""

    def __init__(self, llm_service: MultiVendorLLMService):
        self.llm_service = llm_service

    def get_prompt_template(self) -> PromptTemplate:
        """æ„å»ºPromptæ¨¡æ¿"""
        template = """
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æµ‹è¯•å·¥ç¨‹å¸ˆ,è´Ÿè´£æ ¹æ®æµ‹è¯•ç‚¹å’Œéœ€æ±‚æ–‡æ¡£ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•ç”¨ä¾‹ã€‚

## éœ€æ±‚æ–‡æ¡£
{requirement_text}

## æµ‹è¯•ç‚¹
{test_points}

## ç”¨ä¾‹æ¨¡æ¿
{template_example}

## ä½ çš„ä»»åŠ¡
ä¸ºæ¯ä¸ªæµ‹è¯•ç‚¹ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•ç”¨ä¾‹,åŒ…æ‹¬:
1. ç”¨ä¾‹æ ‡é¢˜ (æ¸…æ™°æè¿°æµ‹è¯•åœºæ™¯)
2. ä¼˜å…ˆçº§ (P0/P1/P2/P3)
3. å‰ç½®æ¡ä»¶ (æ‰§è¡Œç”¨ä¾‹å‰éœ€è¦æ»¡è¶³çš„æ¡ä»¶)
4. æ“ä½œæ­¥éª¤ (è¯¦ç»†çš„æ“ä½œæ­¥éª¤,åºå·åŒ–)
5. é¢„æœŸç»“æœ (æ¯ä¸ªæ­¥éª¤å¯¹åº”çš„é¢„æœŸç»“æœ,ä¸æ­¥éª¤ä¸€ä¸€å¯¹åº”)

## è¾“å‡ºæ ¼å¼ (JSON)
```json
{{
  "test_cases": [
    {{
      "module_name": "ç™»å½•é¡µé¢",
      "page_name": "ç™»å½•",
      "title": "æ­£å¸¸ç™»å½•æµç¨‹",
      "priority": "p0",
      "case_type": "functional",
      "preconditions": [
        "ç”¨æˆ·å·²æ³¨å†Œ",
        "æ‰‹æœºå·æ ¼å¼æ­£ç¡®"
      ],
      "steps": [
        {{
          "step_number": 1,
          "action": "æ‰“å¼€ç™»å½•é¡µé¢",
          "expected_result": "æ˜¾ç¤ºç™»å½•è¡¨å•,åŒ…å«æ‰‹æœºå·è¾“å…¥æ¡†ã€éªŒè¯ç è¾“å…¥æ¡†ã€ç™»å½•æŒ‰é’®"
        }},
        {{
          "step_number": 2,
          "action": "è¾“å…¥æ­£ç¡®æ‰‹æœºå·13800138000",
          "expected_result": "è¾“å…¥æ¡†æ˜¾ç¤ºæ‰‹æœºå·,æ ¼å¼æ­£ç¡®"
        }}
      ],
      "tags": ["å†’çƒŸæµ‹è¯•", "æ­£äº¤è¯•éªŒ"],
      "estimated_time": 2
    }}
  ]
}}
```

## æ³¨æ„äº‹é¡¹
1. æ“ä½œæ­¥éª¤è¦å…·ä½“,é¿å…æ¨¡ç³Šæè¿° (å¦‚"ç‚¹å‡»æŒ‰é’®"åº”æ˜ç¡®"ç‚¹å‡»å“ªä¸ªæŒ‰é’®")
2. é¢„æœŸç»“æœè¦æ˜ç¡®,å¯éªŒè¯
3. ä¸€ä¸ªç”¨ä¾‹æµ‹è¯•ä¸€ä¸ªä¸»è¦åœºæ™¯,é¿å…æ··åˆå¤šä¸ªåœºæ™¯
4. æ­¥éª¤åºå·è¿ç»­,ä¸è·³å·
5. æ ‡ç­¾è¦å‡†ç¡®,ä¾¿äºåç»­ç­›é€‰

ç°åœ¨,è¯·æ ¹æ®æµ‹è¯•ç‚¹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ã€‚
"""
        return PromptTemplate(
            input_variables=["requirement_text", "test_points", "template_example"],
            template=template,
        )

    async def agenerate_test_cases(
        self,
        requirement_text: str,
        test_points: List[Dict[str, Any]],
        module_page_mapping: Dict[str, str],  # æ¨¡å—-é¡µé¢æ˜ å°„
    ) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹"""
        # 1. è·å–æ¨¡æ¿ç¤ºä¾‹ (ä»æ•°æ®åº“æˆ–é»˜è®¤æ¨¡æ¿)
        template_example = self._get_default_template()

        # 2. æ ¼å¼åŒ–æµ‹è¯•ç‚¹
        test_points_text = "\n".join([
            f"- {tp['title']} (ä¼˜å…ˆçº§: {tp['priority']}, åˆ†ç±»: {tp['category']})"
            for tp in test_points
        ])

        # 3. è·å–LLM
        llm = await self.llm_service.get_llm()

        # 4. æ„å»ºé“¾
        prompt = self.get_prompt_template()
        chain = LLMChain(llm=llm, prompt=prompt)

        # 5. æ‰§è¡Œ
        response = await chain.apredict(
            requirement_text=requirement_text,
            test_points=test_points_text,
            template_example=template_example,
        )

        # 6. è§£æJSON
        import json
        try:
            result = json.loads(response)
            test_cases = result["test_cases"]

            # 7. è¡¥å……æ¨¡å—-é¡µé¢ä¿¡æ¯
            for tc in test_cases:
                tc["module_name"] = module_page_mapping.get("module", "é»˜è®¤æ¨¡å—")
                tc["page_name"] = module_page_mapping.get("page", "é»˜è®¤é¡µé¢")

            return test_cases
        except json.JSONDecodeError:
            raise ValueError("AIè¾“å‡ºçš„æ ¼å¼ä¸ç¬¦åˆè¦æ±‚")

    def _get_default_template(self) -> str:
        """è·å–é»˜è®¤ç”¨ä¾‹æ¨¡æ¿"""
        return """
ç”¨ä¾‹ç¤ºä¾‹:
- æ ‡é¢˜: æ­£å¸¸ç™»å½•æµç¨‹
- ä¼˜å…ˆçº§: P0
- å‰ç½®æ¡ä»¶: ç”¨æˆ·å·²æ³¨å†Œã€æ‰‹æœºå·æ­£å¸¸
- æ­¥éª¤: è¯¦è§éœ€æ±‚æ–‡æ¡£
"""
```

### 4.3 AIæœåŠ¡APIæ¥å£

#### 4.3.1 éœ€æ±‚æ¾„æ¸…API

```python
# backend/app/api/v1/endpoints/ai_requirement.py
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from pydantic import BaseModel

from app.core.db import get_session
from app.services.ai.chains.requirement_clarification_chain import RequirementClarificationChain
from app.services.ai.llm_service import MultiVendorLLMService
from app.models.ai_config import AIProviderConfig

router = APIRouter()

class ClarifyRequest(BaseModel):
    requirement_id: int
    user_input: str
    conversation_history: list = []

class ClarifyResponse(BaseModel):
    response: str
    conversation_history: list
    identified_risks: list[str]

@router.post("/clarify", response_model=ClarifyResponse)
async def clarify_requirement(
    request: ClarifyRequest,
    session: AsyncSession = Depends(get_session),
    current_user: User = Depends(get_current_user),
):
    # 1. è·å–ç”¨æˆ·çš„é»˜è®¤AIé…ç½®
    result = await session.execute(
        select(AIProviderConfig)
        .where(AIProviderConfig.user_id == current_user.id)
        .where(AIProviderConfig.is_default == True)
    )
    ai_config = result.scalar_one_or_none()

    if not ai_config:
        raise HTTPException(status_code=400, detail="è¯·å…ˆé…ç½®AI")

    # 2. åˆå§‹åŒ–LLMæœåŠ¡
    llm_service = MultiVendorLLMService(ai_config.dict())

    # 3. æ‰§è¡Œéœ€æ±‚æ¾„æ¸…
    chain = RequirementClarificationChain(llm_service)
    result = await chain.aclarify_requirement(
        user_input=request.user_input,
        conversation_history=request.conversation_history,
    )

    return ClarifyResponse(**result)
```

#### 4.3.2 æµ‹è¯•ç‚¹ç”ŸæˆAPI

```python
# backend/app/api/v1/endpoints/ai_test_points.py
@router.post("/generate-test-points")
async def generate_test_points(
    requirement_id: int,
    session: AsyncSession = Depends(get_session),
    current_user: User = Depends(get_current_user),
):
    # 1. è·å–éœ€æ±‚
    requirement = await session.get(Requirement, requirement_id)

    # 2. è·å–AIé…ç½®
    ai_config = await get_user_default_ai_config(session, current_user.id)

    # 3. ç”Ÿæˆæµ‹è¯•ç‚¹
    llm_service = MultiVendorLLMService(ai_config.dict())
    chain = TestPointGenerationChain(llm_service)
    test_points = await chain.agenerate_test_points(
        requirement_text=requirement.description,
        requirement_id=requirement_id,
    )

    # 4. ä¿å­˜åˆ°æ•°æ®åº“
    saved_points = []
    for tp in test_points:
        test_point = TestPoint(
            requirement_id=requirement_id,
            **tp,
        )
        session.add(test_point)
        await session.flush()
        saved_points.append(test_point)

    await session.commit()

    return {"test_points": saved_points}
```

#### 4.3.3 æµ‹è¯•ç”¨ä¾‹ç”ŸæˆAPI

```python
# backend/app/api/v1/endpoints/ai_test_cases.py
@router.post("/generate-test-cases")
async def generate_test_cases(
    requirement_id: int,
    module_page_mapping: Dict[str, str],
    session: AsyncSession = Depends(get_session),
    current_user: User = Depends(get_current_user),
):
    # 1. è·å–éœ€æ±‚å’Œæµ‹è¯•ç‚¹
    requirement = await session.get(Requirement, requirement_id)
    result = await session.execute(
        select(TestPoint).where(TestPoint.requirement_id == requirement_id)
    )
    test_points = result.scalars().all()

    # 2. ç”Ÿæˆç”¨ä¾‹
    ai_config = await get_user_default_ai_config(session, current_user.id)
    llm_service = MultiVendorLLMService(ai_config.dict())
    chain = TestCaseGenerationChain(llm_service)
    test_cases = await chain.agenerate_test_cases(
        requirement_text=requirement.description,
        test_points=[tp.dict() for tp in test_points],
        module_page_mapping=module_page_mapping,
    )

    # 3. ä¿å­˜åˆ°æ•°æ®åº“
    saved_cases = []
    for tc in test_cases:
        case_id = generate_case_id(requirement.requirement_id)  # TC-2025-001-001

        test_case = TestCase(
            case_id=case_id,
            requirement_id=requirement_id,
            created_by=current_user.id,
            **tc,
        )
        session.add(test_case)
        await session.flush()

        # 4. æ·»åŠ åˆ°çŸ¥è¯†åº“
        await add_to_knowledge_base(test_case, session)

        saved_cases.append(test_case)

    await session.commit()

    return {"test_cases": saved_cases}
```

---

## äº”ã€å‰ç«¯å®ç°æ–¹æ¡ˆ

### 5.1 å‰ç«¯æ¶æ„

```
frontend/src/pages/functional-test/
â”œâ”€â”€ RequirementManagement.tsx          # éœ€æ±‚ç®¡ç†é¡µé¢
â”œâ”€â”€ TestCaseManagement.tsx             # ç”¨ä¾‹ç®¡ç†é¡µé¢
â”œâ”€â”€ TestCaseMindMap.tsx                # æ€ç»´å¯¼å›¾é¡µé¢
â”œâ”€â”€ KnowledgeBase.tsx                  # çŸ¥è¯†åº“é¡µé¢
â”œâ”€â”€ AIConfig.tsx                       # AIé…ç½®é¡µé¢
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ RequirementEditor.tsx          # éœ€æ±‚ç¼–è¾‘å™¨
â”‚   â”œâ”€â”€ AIClarificationChat.tsx        # AIå¯¹è¯ç»„ä»¶
â”‚   â”œâ”€â”€ TestPointList.tsx              # æµ‹è¯•ç‚¹åˆ—è¡¨
â”‚   â”œâ”€â”€ TestCaseTable.tsx              # ç”¨ä¾‹è¡¨æ ¼
â”‚   â”œâ”€â”€ TestCaseEditor.tsx             # ç”¨ä¾‹ç¼–è¾‘å™¨
â”‚   â”œâ”€â”€ MindMapViewer.tsx              # æ€ç»´å¯¼å›¾æŸ¥çœ‹å™¨
â”‚   â””â”€â”€ ExportDialog.tsx               # å¯¼å‡ºå¯¹è¯æ¡†
â””â”€â”€ hooks/
    â”œâ”€â”€ useAIConversation.ts           # AIå¯¹è¯Hook
    â”œâ”€â”€ useTestCaseGeneration.ts       # ç”¨ä¾‹ç”ŸæˆHook
    â””â”€â”€ useMindMap.ts                  # æ€ç»´å¯¼å›¾Hook
```

### 5.2 æ ¸å¿ƒç»„ä»¶å®ç°

#### 5.2.1 AIå¯¹è¯ç»„ä»¶

```typescript
// frontend/src/pages/functional-test/components/AIClarificationChat.tsx
import React, { useState, useRef, useEffect } from 'react'
import { useMutation } from '@tanstack/react-query'
import { Button } from '@/components/ui/button'
import { Textarea } from '@/components/ui/textarea'
import { ScrollArea } from '@/components/ui/scroll-area'
import { LoadingSpinner } from '@/components/ui/loading-spinner'
import { aiApi } from '@/api/client'

interface Message {
  role: 'user' | 'assistant'
  content: string
  timestamp: Date
}

interface Props {
  requirementId: number
  initialMessages?: Message[]
  onClarificationComplete: (risks: string[]) => void
}

export function AIClarificationChat({
  requirementId,
  initialMessages = [],
  onClarificationComplete,
}: Props) {
  const [messages, setMessages] = useState<Message[]>(initialMessages)
  const [input, setInput] = useState('')
  const [isLoading, setIsLoading] = useState(false)
  const scrollRef = useRef<HTMLDivElement>(null)

  // è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
  useEffect(() => {
    if (scrollRef.current) {
      scrollRef.current.scrollTop = scrollRef.current.scrollHeight
    }
  }, [messages])

  // å‘é€æ¶ˆæ¯
  const { mutate: sendMessage } = useMutation({
    mutationFn: async (userInput: string) => {
      const response = await aiApi.clarifyRequirement({
        requirement_id: requirementId,
        user_input: userInput,
        conversation_history: messages,
      })
      return response.data
    },
    onSuccess: (data) => {
      setMessages([
        ...messages,
        { role: 'user', content: input, timestamp: new Date() },
        { role: 'assistant', content: data.response, timestamp: new Date() },
      ])
      setInput('')

      // è§£æè¯†åˆ«åˆ°çš„é£é™©
      const risks = parseRisksFromResponse(data.response)
      if (risks.length > 0) {
        onClarificationComplete(risks)
      }
    },
    onSettled: () => {
      setIsLoading(false)
    },
  })

  const handleSend = () => {
    if (!input.trim() || isLoading) return
    setIsLoading(true)
    sendMessage(input)
  }

  return (
    <div className="flex h-[600px] flex-col border rounded-lg">
      {/* æ¶ˆæ¯åˆ—è¡¨ */}
      <ScrollArea className="flex-1 p-4" ref={scrollRef}>
        {messages.map((msg, idx) => (
          <div
            key={idx}
            className={`mb-4 ${
              msg.role === 'user' ? 'text-right' : 'text-left'
            }`}
          >
            <div
              className={`inline-block max-w-[80%] rounded-lg p-3 ${
                msg.role === 'user'
                  ? 'bg-blue-500 text-white'
                  : 'bg-gray-100 text-gray-900'
              }`}
            >
              {msg.role === 'assistant' && (
                <div className="mb-1 text-sm text-gray-600">
                  ğŸ‘¤ AIåŠ©æ‰‹
                </div>
              )}
              <div className="whitespace-pre-wrap">{msg.content}</div>
            </div>
          </div>
        ))}
        {isLoading && <LoadingSpinner />}
      </ScrollArea>

      {/* è¾“å…¥æ¡† */}
      <div className="border-t p-4">
        <Textarea
          value={input}
          onChange={(e) => setInput(e.target.value)}
          onKeyDown={(e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
              e.preventDefault()
              handleSend()
            }
          }}
          placeholder="è¾“å…¥ä½ çš„å›å¤... (Enterå‘é€, Shift+Enteræ¢è¡Œ)"
          rows={3}
          disabled={isLoading}
        />
        <div className="mt-2 flex justify-end gap-2">
          <Button
            onClick={handleSend}
            disabled={!input.trim() || isLoading}
          >
            å‘é€
          </Button>
        </div>
      </div>
    </div>
  )
}

// è§£æAIå“åº”ä¸­çš„é£é™©ç‚¹
function parseRisksFromResponse(response: string): string[] {
  const risks: string[] = []
  const riskSection = response.match(/### âš ï¸ è¯†åˆ«åˆ°çš„é£é™©\n([\s\S]+?)(?=\n###|$)/)
  if (riskSection) {
    const riskItems = riskSection[1].match(/- (.+)/g)
    if (riskItems) {
      risks.push(...riskItems.map((item) => item.replace('- ', '')))
    }
  }
  return risks
}
```

#### 5.2.2 æ€ç»´å¯¼å›¾ç»„ä»¶

```typescript
// frontend/src/pages/functional-test/components/MindMapViewer.tsx
import React, { useCallback, useMemo } from 'react'
import ReactFlow, {
  Node,
  Edge,
  addEdge,
  Connection,
  useNodesState,
  useEdgesState,
  Controls,
  Background,
  MiniMap,
} from 'reactflow'
import 'reactflow/dist/style.css'

interface TestCase {
  id: string
  title: string
  module_name: string
  page_name: string
  priority: string
  steps: Array<{ step_number: number; action: string }>
}

interface Props {
  testCases: TestCase[]
  onNodeClick: (nodeId: string) => void
}

export function MindMapViewer({ testCases, onNodeClick }: Props) {
  // æ„å»ºæ€ç»´å¯¼å›¾èŠ‚ç‚¹å’Œè¾¹
  const { nodes: initialNodes, edges: initialEdges } = useMemo(() => {
    const nodes: Node[] = []
    const edges: Edge[] = []

    // æ ¹èŠ‚ç‚¹ (éœ€æ±‚)
    nodes.push({
      id: 'root',
      type: 'input',
      data: { label: 'ç”¨æˆ·ç™»å½•åŠŸèƒ½ä¼˜åŒ–\nREQ-2025-001' },
      position: { x: 0, y: 0 },
      style: { backgroundColor: '#1890ff', color: 'white', fontSize: 16 },
    })

    // æŒ‰æ¨¡å—åˆ†ç»„
    const moduleGroups = testCases.reduce((acc, tc) => {
      if (!acc[tc.module_name]) {
        acc[tc.module_name] = {}
      }
      if (!acc[tc.module_name][tc.page_name]) {
        acc[tc.module_name][tc.page_name] = []
      }
      acc[tc.module_name][tc.page_name].push(tc)
      return acc
    }, {} as Record<string, Record<string, TestCase[]>>)

    // æ¨¡å—èŠ‚ç‚¹
    let xOffset = 0
    Object.entries(moduleGroups).forEach(([moduleName, pages], moduleIdx) => {
      const moduleId = `module-${moduleIdx}`
      nodes.push({
        id: moduleId,
        data: { label: `${moduleName}\n(${Object.values(pages).flat().length}æ¡)` },
        position: { x: xOffset, y: 150 },
        style: { backgroundColor: '#52c41a', color: 'white' },
      })
      edges.push({ id: `root-${moduleId}`, source: 'root', target: moduleId })

      // é¡µé¢èŠ‚ç‚¹
      let yOffset = 0
      Object.entries(pages).forEach(([pageName, cases], pageIdx) => {
        const pageId = `page-${moduleIdx}-${pageIdx}`
        nodes.push({
          id: pageId,
          data: { label: `${pageName}\n(${cases.length}æ¡)` },
          position: { x: xOffset, y: 300 + yOffset },
          style: { backgroundColor: '#faad14', color: 'white' },
        })
        edges.push({ id: `${moduleId}-${pageId}`, source: moduleId, target: pageId })

        // ç”¨ä¾‹èŠ‚ç‚¹
        cases.forEach((tc, caseIdx) => {
          const caseId = `case-${tc.id}`
          nodes.push({
            id: caseId,
            data: {
              label: `${tc.title}\nä¼˜å…ˆçº§: ${tc.priority.toUpperCase()}`,
            },
            position: { x: xOffset + (caseIdx % 2) * 250, y: 450 + yOffset + Math.floor(caseIdx / 2) * 80 },
            style: {
              backgroundColor: tc.priority === 'p0' ? '#f5222d' : '#1890ff',
              color: 'white',
              fontSize: 12,
            },
          })
          edges.push({ id: `${pageId}-${caseId}`, source: pageId, target: caseId })
        })

        yOffset += 150
      })

      xOffset += 500
    })

    return { nodes, edges }
  }, [testCases])

  const [nodes, setNodes, onNodesChange] = useNodesState(initialNodes)
  const [edges, setEdges, onEdgesChange] = useEdgesState(initialEdges)

  const onConnect = useCallback(
    (params: Connection) => setEdges((eds) => addEdge(params, eds)),
    [setEdges]
  )

  const onNodeClickHandler = useCallback(
    (event: React.MouseEvent, node: Node) => {
      if (node.id.startsWith('case-')) {
        onNodeClick(node.id)
      }
    },
    [onNodeClick]
  )

  return (
    <div className="h-[800px] w-full border">
      <ReactFlow
        nodes={nodes}
        edges={edges}
        onNodesChange={onNodesChange}
        onEdgesChange={onEdgesChange}
        onConnect={onConnect}
        onNodeClick={onNodeClickHandler}
        fitView
      >
        <Controls />
        <MiniMap />
        <Background variant="dots" gap={12} size={1} />
      </ReactFlow>
    </div>
  )
}
```

#### 5.2.3 å¯¼å‡ºåŠŸèƒ½ç»„ä»¶

```typescript
// frontend/src/pages/functional-test/components/ExportDialog.tsx
import React, { useState } from 'react'
import { Button } from '@/components/ui/button'
import { Checkbox } from '@/components/ui/checkbox'
import { api } from '@/api/client'

interface Props {
  testCases: TestCase[]
  requirement: Requirement
  open: boolean
  onClose: () => void
}

export function ExportDialog({ testCases, requirement, open, onClose }: Props) {
  const [formats, setFormats] = useState({
    csv: true,
    excel: false,
    markdown: false,
    pdf: false,
  })

  const handleExport = async () => {
    for (const [format, enabled] of Object.entries(formats)) {
      if (enabled) {
        await api.exportTestCases({
          requirement_id: requirement.id,
          format,
          include_ids: true,
          include_module_id: true,
        })

        // ä¸‹è½½æ–‡ä»¶
        // ...
      }
    }
    onClose()
  }

  return (
    <Dialog open={open} onOpenChange={onClose}>
      <DialogContent>
        <DialogHeader>
          <DialogTitle>å¯¼å‡ºæµ‹è¯•ç”¨ä¾‹</DialogTitle>
        </DialogHeader>

        <div className="space-y-4">
          <div>
            <label className="mb-2 block text-sm font-medium">å¯¼å‡ºæ ¼å¼</label>
            <div className="space-y-2">
              <label className="flex items-center space-x-2">
                <Checkbox
                  checked={formats.csv}
                  onChange={(e) => setFormats({ ...formats, csv: e.target.checked })}
                />
                <span>CSV (å¯¼å…¥ç¦…é“)</span>
              </label>
              <label className="flex items-center space-x-2">
                <Checkbox
                  checked={formats.excel}
                  onChange={(e) => setFormats({ ...formats, excel: e.target.checked })}
                />
                <span>Excel (XLSX)</span>
              </label>
              <label className="flex items-center space-x-2">
                <Checkbox
                  checked={formats.markdown}
                  onChange={(e) => setFormats({ ...formats, markdown: e.target.checked })}
                />
                <span>Markdown (.md)</span>
              </label>
              <label className="flex items-center space-x-2">
                <Checkbox
                  checked={formats.pdf}
                  onChange={(e) => setFormats({ ...formats, pdf: e.target.checked })}
                />
                <span>PDF (å¸¦å°é¢å’Œç›®å½•)</span>
              </label>
            </div>
          </div>

          <div>
            <label className="mb-2 block text-sm font-medium">æ–‡ä»¶å‘½å</label>
            <Input
              defaultValue={`æµ‹è¯•ç”¨ä¾‹_${requirement.requirement_id}_${requirement.name}_${new Date().toISOString().split('T')[0]}`}
            />
          </div>
        </div>

        <DialogFooter>
          <Button variant="outline" onClick={onClose}>
            å–æ¶ˆ
          </Button>
          <Button onClick={handleExport}>å¯¼å‡º</Button>
        </DialogFooter>
      </DialogContent>
    </Dialog>
  )
}
```

---

## å…­ã€éƒ¨ç½²æ–¹æ¡ˆ

### 6.1 ç¯å¢ƒå˜é‡é…ç½®

```bash
# backend/.env

# æ•°æ®åº“
DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/sisyphus

# Redis
REDIS_URL=redis://localhost:6379/0

# MinIO
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=sisyphus-files

# AIé…ç½® (å¯é€‰,å¦‚æœä¸é…ç½®åˆ™ä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰é…ç½®)
# OPENAI_API_KEY=sk-...
# ANTHROPIC_API_KEY=sk-...

# å‘é‡åŒ–é…ç½®
EMBEDDING_MODEL=openai  # openai/huggingface
EMBEDDING_MODEL_NAME=text-embedding-3-small

# åº”ç”¨é…ç½®
SECRET_KEY=your-secret-key
AUTH_DISABLED=true
```

### 6.2 Docker Composeé…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  postgres:
    image: pgvector/pgvector:pg15
    environment:
      POSTGRES_DB: sisyphus
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"

  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio_data:/data

  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql+asyncpg://postgres:password@postgres:5432/sisyphus
      - REDIS_URL=redis://redis:6379/0
      - MINIO_ENDPOINT=minio:9000
    depends_on:
      - postgres
      - redis
      - minio
    volumes:
      - ./backend:/app

  frontend:
    build: ./frontend
    ports:
      - "5173:5173"
    depends_on:
      - backend

volumes:
  postgres_data:
  minio_data:
```

### 6.3 å¯åŠ¨æ­¥éª¤

```bash
# 1. å¯åŠ¨åŸºç¡€è®¾æ–½
docker compose up -d postgres redis minio

# 2. ç­‰å¾…æ•°æ®åº“å¯åŠ¨å,å®‰è£…pgvectoræ‰©å±•
docker exec -it sisyphus-postgres-1 psql -U postgres -d sisyphus -c "CREATE EXTENSION IF NOT EXISTS vector;"

# 3. è¿è¡Œæ•°æ®åº“è¿ç§»
cd backend
alembic upgrade head

# 4. å¯åŠ¨åç«¯
conda activate platform-auto
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# 5. å¯åŠ¨å‰ç«¯ (æ–°ç»ˆç«¯)
cd frontend
npm run dev

# 6. è®¿é—®åº”ç”¨
open http://localhost:5173
```

---

## ä¸ƒã€æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ

### 7.1 æ•°æ®åº“ä¼˜åŒ–

1. **å‘é‡ç´¢å¼•ä¼˜åŒ–**
   ```sql
   -- æ ¹æ®æ•°æ®é‡è°ƒæ•´listså‚æ•°
   -- æ•°æ®é‡ < 100ä¸‡: lists = 100
   -- æ•°æ®é‡ 100ä¸‡-1000ä¸‡: lists = 1000
   CREATE INDEX idx_knowledge_embedding ON test_case_knowledge
   USING ivfflat (embedding vector_cosine_ops)
   WITH (lists = 1000);
   ```

2. **æŸ¥è¯¢ä¼˜åŒ–**
   ```python
   # é™åˆ¶å‘é‡æ£€ç´¢è¿”å›æ•°é‡
   similar_cases = await vector_store_service.asimilarity_search(
       query=query_text,
       k=10,  # åªè¿”å›æœ€ç›¸å…³çš„å‰10æ¡
       score_threshold=0.7,  # ç›¸ä¼¼åº¦é˜ˆå€¼
   )
   ```

3. **è¿æ¥æ± é…ç½®**
   ```python
   # backend/app/core/db.py
   engine = create_async_engine(
       DATABASE_URL,
       pool_size=20,  # è¿æ¥æ± å¤§å°
       max_overflow=40,  # æœ€å¤§æº¢å‡ºè¿æ¥æ•°
       pool_pre_ping=True,  # è¿æ¥å¥åº·æ£€æŸ¥
   )
   ```

### 7.2 AIè°ƒç”¨ä¼˜åŒ–

1. **Tokenç¼“å­˜**
   ```python
   from functools import lru_cache

   @lru_cache(maxsize=100)
   async def get_cached_embedding(text: str):
       return await embedding_service.embed_text(text)
   ```

2. **æ‰¹é‡å¤„ç†**
   ```python
   # æ‰¹é‡å‘é‡åŒ–,å‡å°‘APIè°ƒç”¨æ¬¡æ•°
   embeddings = await embedding_service.embed_texts(
       texts=[case1_text, case2_text, case3_text, ...]  # ä¸€æ¬¡å¤„ç†å¤šä¸ª
   )
   ```

3. **å¼‚æ­¥ä»»åŠ¡**
   ```python
   # ç”¨Celeryå¼‚æ­¥å¤„ç†è€—æ—¶ä»»åŠ¡
   @celery_app.task
   def generate_test_cases_task(requirement_id: int):
       # ç”¨ä¾‹ç”Ÿæˆå¯èƒ½éœ€è¦30s+,æ”¾åœ¨åå°ä»»åŠ¡
       pass
   ```

### 7.3 å‰ç«¯ä¼˜åŒ–

1. **è™šæ‹Ÿæ»šåŠ¨**
   ```typescript
   // ç”¨ä¾‹åˆ—è¡¨ä½¿ç”¨è™šæ‹Ÿæ»šåŠ¨
   import { useVirtualizer } from '@tanstack/react-virtual'

   const virtualizer = useVirtualizer({
       count: testCases.length,
       getScrollElement: () => parentRef.current,
       estimateSize: () => 100,  // æ¯è¡Œé«˜åº¦
       overscan: 5,  // é¢å¤–æ¸²æŸ“5è¡Œ
   })
   ```

2. **æµå¼è¾“å‡º**
   ```typescript
   // AIå“åº”ä½¿ç”¨Server-Sent Eventsæµå¼è¾“å‡º
   const eventSource = new EventSource('/api/v1/ai/clarify-stream')
   eventSource.onmessage = (event) => {
       const chunk = JSON.parse(event.data)
       setMessages((prev) => [...prev, chunk])
   }
   ```

---

## å…«ã€å®‰å…¨æ–¹æ¡ˆ

### 8.1 API KeyåŠ å¯†å­˜å‚¨

```python
# backend/app/core/security.py
from cryptography.fernet import Fernet
from app.core.config import settings

# ç”ŸæˆåŠ å¯†å¯†é’¥ (åœ¨åº”ç”¨å¯åŠ¨æ—¶ç”Ÿæˆä¸€æ¬¡)
ENCRYPTION_KEY = Fernet.generate_key()
cipher_suite = Fernet(ENCRYPTION_KEY)

def encrypt_api_key(api_key: str) -> str:
    """åŠ å¯†API Key"""
    encrypted = cipher_suite.encrypt(api_key.encode())
    return encrypted.decode()

def decrypt_api_key(encrypted_key: str) -> str:
    """è§£å¯†API Key"""
    decrypted = cipher_suite.decrypt(encrypted_key.encode())
    return decrypted.decode()
```

### 8.2 æƒé™æ§åˆ¶

```python
# backend/app/api/v1/endpoints/ai_test_cases.py
from app.api.deps import get_current_user

@router.post("/generate-test-cases")
async def generate_test_cases(
    requirement_id: int,
    session: AsyncSession = Depends(get_session),
    current_user: User = Depends(get_current_user),  # å¿…é¡»ç™»å½•
):
    # éªŒè¯ç”¨æˆ·æ˜¯å¦æœ‰æƒé™è®¿é—®è¯¥éœ€æ±‚
    requirement = await session.get(Requirement, requirement_id)
    if requirement.created_by != current_user.id:
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®è¯¥éœ€æ±‚")

    # ç»§ç»­å¤„ç†...
```

### 8.3 æ•æ„Ÿä¿¡æ¯è„±æ•

```python
# API Keyè„±æ•æ˜¾ç¤º
def mask_api_key(api_key: str) -> str:
    """è„±æ•API Key,åªæ˜¾ç¤ºå‰4ä½å’Œå4ä½"""
    if len(api_key) <= 8:
        return "****"
    return f"{api_key[:4]}...{api_key[-4:]}"

# è¿”å›ç»™å‰ç«¯æ—¶è„±æ•
{
    "api_key_encrypted": encrypt_api_key(user_input),
    "api_key_masked": mask_api_key(user_input),  # sk-12...xyz
}
```

---

## ä¹ã€ç›‘æ§ä¸æ—¥å¿—

### 9.1 AIè°ƒç”¨ç›‘æ§

```python
# backend/app/services/ai/monitoring.py
from prometheus_client import Counter, Histogram

# AIè°ƒç”¨æ¬¡æ•°
ai_calls_total = Counter(
    'ai_calls_total',
    'Total AI API calls',
    ['provider', 'model', 'operation']  # OpenAI, gpt-4, requirement_clarification
)

# AIè°ƒç”¨è€—æ—¶
ai_call_duration = Histogram(
    'ai_call_duration_seconds',
    'AI API call duration',
    ['provider', 'model']
)

# Tokenæ¶ˆè€—
ai_tokens_total = Counter(
    'ai_tokens_total',
    'Total AI tokens consumed',
    ['provider', 'token_type']  # input/output
)

# ä½¿ç”¨ç¤ºä¾‹
@ai_call_duration.labels(provider='openai', model='gpt-4').time()
async def call_openai_api():
    ai_calls_total.labels(
        provider='openai',
        model='gpt-4',
        operation='requirement_clarification'
    ).inc()
    # è°ƒç”¨API...
```

### 9.2 æ—¥å¿—è®°å½•

```python
import logging

logger = logging.getLogger(__name__)

@router.post("/generate-test-cases")
async def generate_test_cases(...):
    logger.info(f"User {current_user.id} generating test cases for requirement {requirement_id}")

    try:
        test_cases = await chain.agenerate_test_cases(...)
        logger.info(f"Generated {len(test_cases)} test cases successfully")
        return test_cases
    except Exception as e:
        logger.error(f"Failed to generate test cases: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail="ç”¨ä¾‹ç”Ÿæˆå¤±è´¥")
```

---

## åã€æµ‹è¯•æ–¹æ¡ˆ

### 10.1 å•å…ƒæµ‹è¯•

```python
# tests/test_ai_services.py
import pytest
from app.services.ai.llm_service import MultiVendorLLMService

@pytest.mark.asyncio
async def test_openai_llm():
    """æµ‹è¯•OpenAI LLMåˆå§‹åŒ–"""
    config = {
        "provider_type": "openai",
        "api_key_encrypted": encrypt_api_key("sk-test"),
        "model_name": "gpt-4",
    }
    service = MultiVendorLLMService(config)
    llm = await service.get_llm()
    assert llm is not None

@pytest.mark.asyncio
async def test_requirement_clarification():
    """æµ‹è¯•éœ€æ±‚æ¾„æ¸…é“¾"""
    # ä½¿ç”¨Mocké¿å…çœŸå®APIè°ƒç”¨
    # ...
```

### 10.2 é›†æˆæµ‹è¯•

```python
# tests/test_api_endpoints.py
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_clarify_requirement():
    """æµ‹è¯•éœ€æ±‚æ¾„æ¸…API"""
    response = client.post(
        "/api/v1/ai/clarify",
        json={
            "requirement_id": 1,
            "user_input": "æˆ‘è¦åšä¸€ä¸ªç™»å½•åŠŸèƒ½",
        }
    )
    assert response.status_code == 200
    assert "response" in response.json()
```

---

## åä¸€ã€æˆæœ¬ä¼°ç®—

### 11.1 å¼€å‘æˆæœ¬

| é˜¶æ®µ | å·¥ä½œé‡ | äººå‘˜ | å‘¨æœŸ |
|------|--------|------|------|
| æ•°æ®åº“è®¾è®¡ | 3å¤© | åç«¯ | Week 1 |
| åç«¯APIå¼€å‘ | 2å‘¨ | åç«¯ | Week 1-3 |
| AIé›†æˆ (LangChain) | 1.5å‘¨ | åç«¯ + AIå·¥ç¨‹å¸ˆ | Week 2-3 |
| å‰ç«¯å¼€å‘ | 2å‘¨ | å‰ç«¯ | Week 2-4 |
| è”è°ƒæµ‹è¯• | 1å‘¨ | å…¨å‘˜ | Week 5 |
| **æ€»è®¡** | **6å‘¨** | - | - |

### 11.2 AIæˆæœ¬ä¼°ç®— (ä»¥GPT-4ä¸ºä¾‹)

| æ“ä½œ | Tokenæ¶ˆè€— | å•ä»· | æœˆç”¨é‡ (1000ä¸ªç”¨ä¾‹) | æœˆæˆæœ¬ |
|------|----------|------|-------------------|--------|
| éœ€æ±‚æ¾„æ¸… | 2000 tokens/è½® Ã— 5è½® | $0.03/1K tokens | 100æ¬¡ | $30 |
| æµ‹è¯•ç‚¹ç”Ÿæˆ | 3000 tokens/éœ€æ±‚ | $0.06/1K tokens | 100æ¬¡ | $18 |
| ç”¨ä¾‹ç”Ÿæˆ | 5000 tokens/éœ€æ±‚ | $0.03/1K tokens | 100æ¬¡ | $15 |
| å‘é‡åŒ– | 500 tokens/ç”¨ä¾‹ | $0.00002/1K tokens | 10000æ¬¡ | $0.1 |
| **æ€»è®¡** | - | - | - | **~$63/æœˆ** |

**é™æœ¬æ–¹æ¡ˆ**:
- ä½¿ç”¨GPT-3.5 Turbo (ä¾¿å®œ10å€)
- ä½¿ç”¨é€šä¹‰åƒé—®/æ–‡å¿ƒä¸€è¨€ (ä¾¿å®œ5-10å€)
- æœ¬åœ°éƒ¨ç½²å¼€æºæ¨¡å‹ (ä¸€æ¬¡æ€§æˆæœ¬,æ— APIè°ƒç”¨è´¹ç”¨)

---

## åäºŒã€é£é™©è¯„ä¼°ä¸åº”å¯¹

| é£é™© | å½±å“ | æ¦‚ç‡ | åº”å¯¹æªæ–½ |
|------|------|------|----------|
| AIç”Ÿæˆè´¨é‡ä¸ç¨³å®š | é«˜ | ä¸­ | 1. å¼•å…¥åé¦ˆæœºåˆ¶,æŒç»­ä¼˜åŒ–Prompt<br>2. æ”¯æŒç”¨æˆ·ä¿®æ”¹å’Œè¡¥å……<br>3. è®¾ç½®ç½®ä¿¡åº¦é˜ˆå€¼,ä½äºé˜ˆå€¼äººå·¥å®¡æ ¸ |
| å‘é‡æ£€ç´¢å‡†ç¡®ç‡ä½ | ä¸­ | ä½ | 1. æµ‹è¯•å¤šä¸ªEmbeddingæ¨¡å‹<br>2. è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼<br>3. ç»“åˆå…³é”®è¯æ£€ç´¢ |
| AIæˆæœ¬è¿‡é«˜ | ä¸­ | ä¸­ | 1. ä½¿ç”¨GPT-3.5è€ŒéGPT-4<br>2. ç¼“å­˜å¸¸è§æŸ¥è¯¢ç»“æœ<br>3. æ”¯æŒæœ¬åœ°æ¨¡å‹ |
| pgvectoræ€§èƒ½ç“¶é¢ˆ | ä¸­ | ä½ | 1. ä¼˜åŒ–ç´¢å¼•å‚æ•°<br>2. åˆ†è¡¨å­˜å‚¨<br>3. è€ƒè™‘ä¸“ä¸šå‘é‡æ•°æ®åº“ (å¦‚Milvus) |
| ç”¨æˆ·æ¥å—åº¦ä½ | é«˜ | ä½ | 1. MVPé˜¶æ®µé‚€è¯·æ ¸å¿ƒç”¨æˆ·æµ‹è¯•<br>2. å¿«é€Ÿè¿­ä»£ä¼˜åŒ–<br>3. æä¾›å®Œå–„çš„ä½¿ç”¨æ–‡æ¡£ |

---

## åä¸‰ã€æ€»ç»“ä¸å»ºè®®

### 13.1 æŠ€æœ¯æ–¹æ¡ˆæ€»ç»“

1. **æ¶æ„é€‰å‹**: æ¨èè‡ªç ” + LangChain,ä¿è¯ç”¨æˆ·ä½“éªŒå’Œå¯å®šåˆ¶æ€§
2. **æ•°æ®åº“**: PostgreSQL + pgvector,æ— éœ€é¢å¤–å‘é‡æ•°æ®åº“
3. **AIé›†æˆ**: LangChainç»Ÿä¸€ç¼–æ’,æ”¯æŒå¤šå‚å•†LLM
4. **å‰ç«¯**: React + ReactFlowæ€ç»´å¯¼å›¾,shadcn/uiç»„ä»¶åº“
5. **éƒ¨ç½²**: Docker Composeä¸€é”®éƒ¨ç½²

### 13.2 å®æ–½å»ºè®®

#### é˜¶æ®µ1: MVP (4-6å‘¨)
- âœ… åŸºç¡€AIé…ç½® (OpenAI + é€šä¹‰åƒé—®)
- âœ… éœ€æ±‚æ¾„æ¸… (å¤šè½®å¯¹è¯)
- âœ… æµ‹è¯•ç‚¹ç”Ÿæˆ
- âœ… ç”¨ä¾‹ç”Ÿæˆ (è¡¨æ ¼è§†å›¾)
- âœ… CSV/Excelå¯¼å‡º

#### é˜¶æ®µ2: å®Œæ•´ç‰ˆ (+4å‘¨)
- âœ… æ€ç»´å¯¼å›¾è§†å›¾
- âœ… PDFå¯¼å‡º
- âœ… å¤šAIå‚å•†æ”¯æŒ (5+)
- âœ… çŸ¥è¯†åº“æ£€ç´¢
- âœ… ç”¨ä¾‹è¯„å®¡åä½œ

#### é˜¶æ®µ3: å¢å¼ºç‰ˆ (æŒ‰éœ€)
- âœ… AIæ¨¡å‹å¾®è°ƒ
- âœ… è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬ç”Ÿæˆ
- âœ… å¤šæ¨¡æ€æ”¯æŒ (è¯­éŸ³ã€è§†é¢‘)
- âœ… ç¦…é“APIé›†æˆ

### 13.3 å…³é”®æˆåŠŸå› ç´ 

1. **Promptå·¥ç¨‹**: AIç”Ÿæˆè´¨é‡é«˜åº¦ä¾èµ–Promptè®¾è®¡,éœ€è¦æŒç»­ä¼˜åŒ–
2. **çŸ¥è¯†åº“è´¨é‡**: å†å²ç”¨ä¾‹è¶Šè§„èŒƒ,ç”Ÿæˆæ•ˆæœè¶Šå¥½
3. **ç”¨æˆ·åé¦ˆ**: å»ºç«‹åé¦ˆæœºåˆ¶,å¿«é€Ÿè¿­ä»£ä¼˜åŒ–
4. **æˆæœ¬æ§åˆ¶**: åˆç†é€‰æ‹©AIæ¨¡å‹,é¿å…æˆæœ¬å¤±æ§

### 13.4 åç»­ä¼˜åŒ–æ–¹å‘

1. **æ¨¡å‹å¾®è°ƒ**: åŸºäºä¼ä¸šå†å²æ•°æ®å¾®è°ƒä¸“å±æ¨¡å‹
2. **å¤šæ¨¡æ€**: æ”¯æŒè¯­éŸ³è¾“å…¥éœ€æ±‚ã€è§†é¢‘è®²è§£
3. **è‡ªåŠ¨åŒ–æµ‹è¯•**: ç”Ÿæˆçš„ç”¨ä¾‹ç›´æ¥è½¬æ¢ä¸ºè‡ªåŠ¨åŒ–è„šæœ¬ (Playwright/Cypress)
4. **æ™ºèƒ½è¯„å®¡**: AIè‡ªåŠ¨æ£€æµ‹ç”¨ä¾‹é—æ¼å’Œé”™è¯¯

---

**æ–‡æ¡£ç»“æŸ**

> æœ¬æ–‡æ¡£æä¾›äº†è¯¦ç»†çš„æŠ€æœ¯å®ç°æ–¹æ¡ˆ,å¼€å‘å›¢é˜Ÿå¯ä»¥åŸºäºæ­¤æ–‡æ¡£å¼€å§‹å¼€å‘å·¥ä½œã€‚å¦‚æœ‰ç–‘é—®,è¯·éšæ—¶æ²Ÿé€šã€‚
